var documenterSearchIndex = {"docs":
[{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"EditURL = \"https://github.com/JuliaFolds/FLoops.jl/blob/master/examples/howto/parallel.jl\"","category":"page"},{"location":"howto/parallel/#How-to-write-*X*-in-parallel.","page":"How to do X in parallel?","title":"How to write X in parallel.","text":"","category":"section"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"using FLoops","category":"page"},{"location":"howto/parallel/#In-place-mutation","page":"How to do X in parallel?","title":"In-place mutation","text":"","category":"section"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"Mutable containers can be allocated in the init expressions (zeros(3) in the example below):","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"local ys  # hide\n@floop for x in 1:10\n    xs = [x, 2x, 3x]\n    @reduce() do (ys = zeros(3); xs)\n        ys .+= xs\n    end\nend\nys","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"Mutating objects allocated in the init expressions is not data race because each basecase \"owns\" such mutable objects.  However, it is incorrect to mutate objects created outside init expressions.","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"See also: What is the difference of @reduce and @init to the approach using state[threadid()]?","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"note: Note\nTechnically, it is correct to mutate objects in the loop body if the objects are protected by a lock.  However, it means that the code block protected by the lock can only be executed by a single task.  For efficient data parallel loops, it is highly recommended to use non-thread-safe data collection (i.e., no lock) and construct the @reduce block that efficiently merge two mutable objects.","category":"page"},{"location":"howto/parallel/#INCORRECT-EXAMPLE","page":"How to do X in parallel?","title":"INCORRECT EXAMPLE","text":"","category":"section"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"This example has data race because the array ys0 is shared across all base cases and mutated in parallel.","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"ys0 = zeros(3)\nlet # hide\n@floop for x in 1:10\n    xs = [x, 2x, 3x]\n    @reduce() do (ys = ys0; xs)\n        ys .+= xs\n    end\nend\nend # hide","category":"page"},{"location":"howto/parallel/#private-variables","page":"How to do X in parallel?","title":"Data race-free reuse of mutable objects using private variables","text":"","category":"section"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"To avoid allocation for each iteration, it is useful to pre-allocate mutable objects and reuse them. We can use @init macro to do this in a data race-free (\"thread-safe\") manner:","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"local ys  # hide\n@floop for x in 1:10\n    @init xs = Vector{typeof(x)}(undef, 3)\n    xs .= (x, 2x, 3x)\n    @reduce() do (ys = zeros(3); xs)\n        ys .+= xs\n    end\nend\nys","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"See also: What is the difference of @reduce and @init to the approach using state[threadid()]?","category":"page"},{"location":"howto/parallel/#Efficient-and-reproducible-usage-patterns-of-random-number-generators","page":"How to do X in parallel?","title":"Efficient and reproducible usage patterns of random number generators","text":"","category":"section"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"Julia's default random number generator (RNG) is data race-free for invoking from multiple threads; i.e., calls like randn() have well-defined behaviors. However, for the performance and reproducibility, it is useful to directly creating the RNGs. A convenient approach to this is to use a private variable:","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"using Random\n\nMersenneTwister()  # the first invocation of `MersenneTwister` is not data race-free\n\nlet # hide\n@floop for _ in 1:10\n    @init rng = MersenneTwister()\n    @reduce(s += rand(rng))\nend\nend # hide","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"The above approach may work well for exploratory purposes. However, it has a problem that the computation is not reproducible and each invocation of MersenneTwister requires an I/O (reading /dev/urandom). These problems can be solved by, for example, using randjump function. First, let us construct ntasks RNGs to be used.","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"using Future\n\nntasks = Threads.nthreads()  # the number of base cases\nrngs = [MersenneTwister(123456789)]\nlet rng = rngs[end]\n    for _ in 2:ntasks\n        rng = Future.randjump(rng, big(10)^20)\n        push!(rngs, rng)\n    end\nend","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"This list of RNGs can be used with some input array by manually partitioning the input into ntasks chunks:","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"let # hide\nxs = 1:10  # input\nchunks = Iterators.partition(xs, cld(length(xs), length(rngs)))\n@floop ThreadedEx(basesize = 1) for (rng, chnk) in zip(rngs, chunks)\n    y = 0\n    for _ in chnk\n        y += rand(rng)\n    end\n    @reduce(s += y)\nend\nend # hide","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"Note that the above pattern can also be used with @threads for loop.","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"Another approach is to use a counter-based RNG as illustrated in Monte-Carlo π · FoldsCUDA. This approach works both on CPU and GPU.","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"","category":"page"},{"location":"howto/parallel/","page":"How to do X in parallel?","title":"How to do X in parallel?","text":"This page was generated using Literate.jl.","category":"page"},{"location":"tutorials/sequential/#tutorials-sequential","page":"Sequential loops","title":"Sequential (single-thread) loops","text":"","category":"section"},{"location":"tutorials/sequential/","page":"Sequential loops","title":"Sequential loops","text":"Simply wrap a for loop and its initialization part by @floop:","category":"page"},{"location":"tutorials/sequential/","page":"Sequential loops","title":"Sequential loops","text":"julia> using FLoops  # exports @floop macro\n\njulia> @floop begin\n           s = 0\n           for x in 1:3\n               s += x\n           end\n       end\n       s\n6","category":"page"},{"location":"tutorials/sequential/","page":"Sequential loops","title":"Sequential loops","text":"When accumulating into pre-defined variables, simply list them between begin and for.  @floop also works with multiple accumulators.","category":"page"},{"location":"tutorials/sequential/","page":"Sequential loops","title":"Sequential loops","text":"julia> using FLoops\n\njulia> s = 6;\n\njulia> @floop begin\n           s\n           p = 1\n           for x in 4:5\n               s += x\n               p *= x\n           end\n       end\n       s\n15\n\njulia> p\n20","category":"page"},{"location":"tutorials/sequential/","page":"Sequential loops","title":"Sequential loops","text":"The begin ... end block can be omitted if the for loop does not require local variables to carry the state:","category":"page"},{"location":"tutorials/sequential/","page":"Sequential loops","title":"Sequential loops","text":"julia> using FLoops\n\njulia> @floop for x in 1:3\n           @show x\n       end\nx = 1\nx = 2\nx = 3","category":"page"},{"location":"reference/syntax/#Syntax-supported-by-@floop","page":"Syntax","title":"Syntax supported by @floop","text":"","category":"section"},{"location":"reference/syntax/","page":"Syntax","title":"Syntax","text":"DocTestSetup = quote\n    using FLoops\nend","category":"page"},{"location":"reference/syntax/#continue","page":"Syntax","title":"continue","text":"","category":"section"},{"location":"reference/syntax/","page":"Syntax","title":"Syntax","text":"julia> @floop for x in 1:3\n           if x == 1\n               println(\"continue\")\n               continue\n           end\n           @show x\n       end\ncontinue\nx = 2\nx = 3","category":"page"},{"location":"reference/syntax/#break","page":"Syntax","title":"break","text":"","category":"section"},{"location":"reference/syntax/","page":"Syntax","title":"Syntax","text":"julia> @floop for x in 1:3\n           @show x\n           if x == 2\n               println(\"break\")\n               break\n           end\n       end\nx = 1\nx = 2\nbreak","category":"page"},{"location":"reference/syntax/#return","page":"Syntax","title":"return","text":"","category":"section"},{"location":"reference/syntax/","page":"Syntax","title":"Syntax","text":"julia> function demo()\n           @floop for x in 1:3\n               @show x\n               if x == 2\n                   return \"return\"\n               end\n           end\n       end\n       demo()\nx = 1\nx = 2\n\"return\"","category":"page"},{"location":"reference/syntax/#@goto","page":"Syntax","title":"@goto","text":"","category":"section"},{"location":"reference/syntax/","page":"Syntax","title":"Syntax","text":"julia> begin\n       @floop for x in 1:3\n           x == 1 && @goto L1\n           @show x\n           if x == 2\n               @goto L2\n           end\n           @label L1\n       end\n       println(\"This is not going to be printed.\")\n       @label L2\n       println(\"THIS is going to be printed.\")\n       end\nx = 2\nTHIS is going to be printed.","category":"page"},{"location":"reference/syntax/","page":"Syntax","title":"Syntax","text":"DocTestSetup = nothing","category":"page"},{"location":"reference/api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"reference/api/#@floop","page":"API","title":"@floop","text":"","category":"section"},{"location":"reference/api/","page":"API","title":"API","text":"FLoops.@floop","category":"page"},{"location":"reference/api/#FLoops.@floop","page":"API","title":"FLoops.@floop","text":"@floop begin\n    s₁ = initialization of s₁\n    s₂  # pre-initialized variable\n    ...\n    for x in xs, ...\n        ...\n    end\nend\n\n@floop begin ... end expects a (possibly empty) series of assignments or variable declaration (as in s₂ above) followed by a for loop.\n\nWhen there is no induction variables, begin ... end can be omitted:\n\n@floop for x in xs, ...\n    ...\nend\n\nUse @reduce for parallel execution:\n\n@floop for x in xs, ...\n    ...\n    @reduce ...\nend\n\n@floop can also take an executor argument (which should be an instance of executor such as SequentialEx, ThreadedEx and DistributedEx) or a nothing (indicating an appropriate parallel executor):\n\n@floop executor for x in xs, ...\n    ...\n    @reduce ...\nend\n\nSee the module docstring of FLoops for examples.\n\n\n\n\n\n","category":"macro"},{"location":"reference/api/#@reduce","page":"API","title":"@reduce","text":"","category":"section"},{"location":"reference/api/","page":"API","title":"API","text":"FLoops.@reduce","category":"page"},{"location":"reference/api/#FLoops.@reduce","page":"API","title":"FLoops.@reduce","text":"@reduce() do (acc₁ [= init₁]; x₁), ..., (accₙ [= initₙ]; xₙ)\n    ...\nend\n@reduce(acc₁ ⊗₁= x₁, ..., accₙ ⊗ₙ= xₙ)\n@reduce(acc₁ .⊗₁= x₁, ..., accₙ .⊗ₙ= xₙ)\n@reduce(acc₁ = ⊗₁(init₁, x₁), ..., accₙ = ⊗ₙ(initₙ, xₙ))\n@reduce(acc₁ .= (⊗₁).(init₁, x₁), ..., accₙ = (⊗ₙ).(initₙ, xₙ))\n\nDeclare how accumulators are updated in the sequential basecase and how the resulting accumulators from two basecases are combined.\n\nThe arguments accᵢ and xᵢ must be symbols except for xᵢ of the last three forms in which an expression can be used at xᵢ.\n\nIn the first form,\n\nfunction ((acc₁, acc₂, ..., accₙ), (x₁, x₂, ..., xₙ))\n    ...  # body of the `do` block\n    return (acc₁, acc₂, ..., accₙ)\nend\n\nshould be an associative function.\n\nIn the last three forms, every binary operation ⊗ᵢ should be an associative function.\n\nIf initᵢ is specified, the tuple (init₁, init₂, ..., initₙ) should be the identify of the related associative function.  accᵢ = initᵢ is evaluated for each basecase (each Task) in the beginning.\n\nConsider a loop with the following form\n\n@floop for ...\n    # code computing (x₁, x₂, ..., xₙ)\n    @reduce() do (acc₁ = init₁; x₁), ..., (accₙ = initₙ; xₙ)\n        # code updating (acc₁, acc₂, ..., accₙ) using (x₁, x₂, ..., xₙ)\n    end\nend\n\nThis is converted to\n\nacc₁ = init₁\n...\naccₙ = initₙ\nfor ...\n    # code computing (x₁, x₂, ..., xₙ)\n    # code updating (acc₁, acc₂, ..., accₙ) using (x₁, x₂, ..., xₙ)\nend\n\nfor computing (acc₁, acc₂, ..., accₙ) of each basecase.  The accumulators accᵢ of two basecases are combined using \"code updating (acc₁, acc₂, ..., accₙ) using (x₁, x₂, ..., xₙ)\" where (x₁, x₂, ..., xₙ) are replaced with (acc₁, acc₂, ..., accₙ) of the next basecase.  Note that \"code computing (x₁, x₂, ..., xₙ)\" is not used for combining the basecases.\n\nExamples\n\n@reduce() do (vmax=-Inf; v), (imax=0; i)\n    if isless(vmax, v)\n        vmax = v\n        imax = i\n    end\nend\n\n@reduce(s += y, p *= y)\n\n@reduce(xs = append!!(EmptyVector(), x), ys = append!!(EmptyVector(), y))\n\n\n\n\n\n","category":"macro"},{"location":"reference/api/#@init","page":"API","title":"@init","text":"","category":"section"},{"location":"reference/api/","page":"API","title":"API","text":"FLoops.@init","category":"page"},{"location":"reference/api/#FLoops.@init","page":"API","title":"FLoops.@init","text":"@init begin\n    pv₁ = init₁\n    ...\n    pvₙ = initₙ\nend\n\nInitialize private variables pvᵢ with initializer expression initᵢ for each task. This can be used for mutating objects in a data race-free manner.\n\n\n\n\n\n","category":"macro"},{"location":"reference/api/#executor","page":"API","title":"SequentialEx, ThreadedEx and DistributedEx executors","text":"","category":"section"},{"location":"reference/api/","page":"API","title":"API","text":"An executor controls how a given @floop is executed. FLoops.jl re-exports SequentialEx, ThreadedEx and DistributedEx executors from Transducers.jl.","category":"page"},{"location":"reference/api/","page":"API","title":"API","text":"See also:","category":"page"},{"location":"reference/api/","page":"API","title":"API","text":"@floop tutorials on executors\nExecutor section in Transducers.jl's glossary.\nTransducers.SequentialEx\nTransducers.ThreadedEx\nTransducers.DistributedEx\nHow is a parallel @floop executed? What is the scheduling strategy?","category":"page"},{"location":"reference/api/#FLoops.assistant","page":"API","title":"FLoops.assistant","text":"","category":"section"},{"location":"reference/api/","page":"API","title":"API","text":"FLoops.assistant","category":"page"},{"location":"reference/api/#FLoops.assistant","page":"API","title":"FLoops.assistant","text":"FLoops.assistant(mode::Symbol)\nFLoops.assistant(enable::Bool)\n\nSet assistant mode; i.e., what to do when FLoops.jl finds a problematic usage pattern.\n\nAssistant modes:\n\n:ignore: do nothing\n:warn: print warning once\n:warn_always: print warning always\n:error: throw an error\n\nFLoops.assistant(false) is equivalent to FLoops.assistant(:ignore) and FLoops.assistant(true) is equivalent to FLoops.assistant(:warn).\n\n\n\n\n\n","category":"function"},{"location":"reference/reduction/","page":"Parallelizable reduction (WIP)","title":"Parallelizable reduction (WIP)","text":"EditURL = \"https://github.com/JuliaFolds/FLoops.jl/blob/master/examples/reference/reduction.jl\"","category":"page"},{"location":"reference/reduction/#Parallelizable-reduction-using-@reduce","page":"Parallelizable reduction (WIP)","title":"Parallelizable reduction using @reduce","text":"","category":"section"},{"location":"reference/reduction/","page":"Parallelizable reduction (WIP)","title":"Parallelizable reduction (WIP)","text":"warning: Warning\nThis page is still work-in-progress.","category":"page"},{"location":"reference/reduction/","page":"Parallelizable reduction (WIP)","title":"Parallelizable reduction (WIP)","text":"using FLoops","category":"page"},{"location":"reference/reduction/#ref-reduce-do","page":"Parallelizable reduction (WIP)","title":"@reduce() do ... end syntax","text":"","category":"section"},{"location":"reference/reduction/","page":"Parallelizable reduction (WIP)","title":"Parallelizable reduction (WIP)","text":"@floop for x in 1:10\n    y = 2x\n    @reduce() do (acc; y)\n        acc += y\n    end\nend\nacc","category":"page"},{"location":"reference/reduction/#Argument-symbols-must-be-unique-within-a-@reduce-block","page":"Parallelizable reduction (WIP)","title":"Argument symbols must be unique within a @reduce block","text":"","category":"section"},{"location":"reference/reduction/","page":"Parallelizable reduction (WIP)","title":"Parallelizable reduction (WIP)","text":"err = try # hide\n@eval begin # hide\n@floop for x in 1:10\n    @reduce() do (a; x), (b; x)\n        a += x\n        b *= x\n    end\nend\nend # hide\ncatch _err; _err; end # hide\nprint(stdout, \"ERROR: \") # hide\nshowerror(stdout, err) # hide","category":"page"},{"location":"reference/reduction/","page":"Parallelizable reduction (WIP)","title":"Parallelizable reduction (WIP)","text":"The argument should be manually duplicated when using the same variable that would be merged into multiple accumulators:","category":"page"},{"location":"reference/reduction/","page":"Parallelizable reduction (WIP)","title":"Parallelizable reduction (WIP)","text":"@floop for x in 1:10\n    y = x\n    @reduce() do (a; x), (b; y)\n        a += x\n        b *= y\n    end\nend\n(a, b)","category":"page"},{"location":"reference/reduction/","page":"Parallelizable reduction (WIP)","title":"Parallelizable reduction (WIP)","text":"If two accumulators do not interact as in the case above, it is recommended to use two @reduce() do blocks to clarify that they are independent reductions:","category":"page"},{"location":"reference/reduction/","page":"Parallelizable reduction (WIP)","title":"Parallelizable reduction (WIP)","text":"@floop for x in 1:10\n    @reduce() do (a; x)\n        a += x\n    end\n    @reduce() do (b; x)\n        b *= x\n    end\nend\n(a, b)","category":"page"},{"location":"reference/reduction/","page":"Parallelizable reduction (WIP)","title":"Parallelizable reduction (WIP)","text":"","category":"page"},{"location":"reference/reduction/","page":"Parallelizable reduction (WIP)","title":"Parallelizable reduction (WIP)","text":"This page was generated using Literate.jl.","category":"page"},{"location":"","page":"FLoops.jl","title":"FLoops.jl","text":"CurrentModule = FLoops","category":"page"},{"location":"#FLoops.jl","page":"FLoops.jl","title":"FLoops.jl","text":"","category":"section"},{"location":"","page":"FLoops.jl","title":"FLoops.jl","text":"FLoops","category":"page"},{"location":"#FLoops.FLoops","page":"FLoops.jl","title":"FLoops.FLoops","text":"FLoops: fold for humans™\n\n(Image: Dev) (Image: GitHub Actions)\n\nFLoops.jl provides a macro @floop. It can be used to generate a fast generic sequential and parallel iteration over complex collections.\n\nFurthermore, the loop written in @floop can be executed with any compatible executors. See FoldsThreads.jl for various thread-based executors that are optimized for different kinds of loops. FoldsCUDA.jl provides an executor for GPU. FLoops.jl also provide a simple distributed executor.\n\nUsage\n\nSequential (single-thread) loops\n\nSimply wrap a for loop and its initialization part by @floop:\n\njulia> using FLoops  # exports @floop macro\n\njulia> @floop begin\n           s = 0\n           for x in 1:3\n               s += x\n           end\n       end\n       s\n6\n\nFor more examples, see sequential loops tutorial.\n\nParallel loop\n\n@floop is a superset of Threads.@threads (see below) and in particular supports complex reduction with additional syntax @reduce:\n\njulia> @floop for (x, y) in zip(1:3, 1:2:6)\n           a = x + y\n           b = x - y\n           @reduce(s += a, t += b)\n       end\n       (s, t)\n(15, -3)\n\nFor more examples, see parallel loops tutorial.\n\nAdvantages over Threads.@threads\n\n@floop is a superset of Threads.@threads and has a couple of advantages:\n\n@floop supports various input collection types including arrays, dicts, sets, strings, and many iterators from Base.Iterators such as zip and product. More precisely, @floop can generate high-performance parallel iterations for any collections that supports SplittablesBase.jl interface.\nWith FoldsThreads.NondeterministicEx, @floop can even parallelize iterations over non-parallelizable input collections (although it is beneficial only for heavier workload).\nFoldsThreads.jl provides multiple alternative thread-based executors (= loop execution backend) that can be used to tune the performance without touching the loop itself.\nFoldsCUDA.jl provides a simple GPU executor.\n@reduce syntax for supporting complex reduction in a forward-compatible manner\nNote: threadid-based reduction (that is commonly used in conjunction with @threads) may not be forward-compatible to Julia that supports migrating tasks across threads.\nThere is a trick for \"changing\" the effective number of threads without restarting julia using the basesize option.\n\nThe relative disadvantages may be that @floop is much newer than Threads.@threads and has much more flexible internals. These points can contribute to undiscovered bugs.\n\nHow it works\n\n@floop works by converting the native Julia for loop syntax to foldl defined by Transducers.jl.  Unlike foldl defined in Base, foldl defined by Transducers.jl is powerful enough to cover the for loop semantics and more.\n\n\n\n\n\n","category":"module"},{"location":"explanation/faq/#Frequently-asked-questions","page":"FAQ","title":"Frequently asked questions","text":"","category":"section"},{"location":"explanation/faq/#faq-state-threadid","page":"FAQ","title":"What is the difference of @reduce and @init to the approach using state[threadid()]?","text":"","category":"section"},{"location":"explanation/faq/","page":"FAQ","title":"FAQ","text":"It is important to understand that state[threadid()] += f(x) may contain a concurrency bug. If f can yield to the scheduler (e.g., containing an I/O such as println and @debug), this code may not work as you expect, even in a single-threaded julia instance and/or pre-1.3 Julia. This is because the above code is equivalent to","category":"page"},{"location":"explanation/faq/","page":"FAQ","title":"FAQ","text":"i = threadid()\na = state[i]\nb = f(x)\nc = a + b\nstate[i] = c","category":"page"},{"location":"explanation/faq/","page":"FAQ","title":"FAQ","text":"If f can yield to the scheduler, and if there are other tasks with the same threadid that can mutate state, the value stored at state[threadid()] may not be equal to a by the time the last line is executed.","category":"page"},{"location":"explanation/faq/","page":"FAQ","title":"FAQ","text":"Furthermore, if julia supports migration of Task across OS threads at some future version, the above scenario can happen even if f never yields to the scheduler. Therefore, reduction or private state handling using threadid is very discouraged.","category":"page"},{"location":"explanation/faq/","page":"FAQ","title":"FAQ","text":"This caveat does not apply to @reduce and @init used in FLoops.jl and in general to the reduction mechanism used by JuliaFolds packages. Furthermore, since @reduce and @init do not depend on a particular execution mechanism (i.e., threading), @floop can generate the code that can be efficiently executed in distributed and GPU executors.","category":"page"},{"location":"explanation/faq/","page":"FAQ","title":"FAQ","text":"note: Note\nThe problem discussed above can also be worked around by, e.g., using Threads.@threads for (since it spawns exactly nthreads() tasks and ensures that each task is scheduled on each OS thread, as of Julia 1.6) and making sure that state is not shared across multiple loops.","category":"page"},{"location":"explanation/faq/#faq-exeuctor","page":"FAQ","title":"How is a parallel @floop executed? What is the scheduling strategy?","text":"","category":"section"},{"location":"explanation/faq/","page":"FAQ","title":"FAQ","text":"It depends on the exact executor used. For example, a parallel loop can be executed in a single thread by using SequentialEx executor. (Thus, a \"parallel loop\" should really be called a parallelizable loop. But it is mouthful so we use the phrase \"parallel loop\".) Furthermore, the default executor is determined by the input collection types; e.g., if FoldsCUDA.jl is loaded, reductions on CuArray are executed on GPU with CUDAEx executor.","category":"page"},{"location":"explanation/faq/","page":"FAQ","title":"FAQ","text":"But, by default (i.e., if no special executor is registered for the input collection type), parallel loops are run with ThreadedEx executor. How this executor works is an implementation detail. However, as of writing (Transducers.jl 0.4.60), this executor takes a divide-and-conquer approach. That is to say, it first recursively halves the input collection until the each part (base case) is smaller or equal to basesize. Each base case is then executed in a single Task. The results of base cases are then combined pair-wise in distinct Tasks (re-using the ones created for reducing the base case). Compared to the sequential scheduling approach taken by Threads.@threads for (as of Julia 1.6), this approach has an advantage that it exhibits a greater parallelism.","category":"page"},{"location":"explanation/faq/","page":"FAQ","title":"FAQ","text":"If the scheduling by ThreadedEx does not yield a desired behavior, you can use FoldsThreads.jl for different executors with different performance characteristics.","category":"page"},{"location":"tutorials/parallel/#tutorials-parallel","page":"Parallel loops","title":"Parallel loops","text":"","category":"section"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"@floop supports parallel loops not only for side-effect (as in Threads.@threads) but also for complex reductions using the optional @reduce syntax.","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"@floop is useful even without @reduce because it supports multiple executors for selecting specific execution mechanisms without rewriting your code. For example, FoldsThreads.jl provides additional rich set of thread-based executors from which you can choose an appropriate executor to maximize the performance of your program. FoldsCUDA.jl provides an executor for GPU. FLoops.jl also provide a simple distributed executor.","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"For in-place update operations (i.e., Threads.@threads-like operations), you can use @floop ThreadedEx() for:","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"julia> using FLoops\n\njulia> function floop_map!(f, ys, xs, ex = ThreadedEx())\n           @floop ex for i in eachindex(ys, xs)\n               @inbounds ys[i] = f(xs[i])\n           end\n           return ys\n       end;\n\njulia> floop_map!(x -> x + 1, zeros(3), 1:3)\n3-element Array{Float64,1}:\n 2.0\n 3.0\n 4.0","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"For a parallel algorithm that requires reductions, you can use @reduce(acc op= x) syntax:","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"julia> using FLoops\n\njulia> @floop for (x, y) in zip(1:3, 1:2:6)\n           a = x + y\n           b = x - y\n           @reduce(s += a, t += b)\n       end\n       (s, t)\n(15, -3)","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"With @reduce, the default executor is ThreadedEx.","category":"page"},{"location":"tutorials/parallel/#Initialization-with-@reduce(acc-op(init,-x))-syntax","page":"Parallel loops","title":"Initialization with @reduce(acc = op(init, x)) syntax","text":"","category":"section"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"Use acc = op(init, x) to specify that the identity element for the binary function op is init:","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"julia> using FLoops\n\njulia> using BangBang  # for `append!!`\n\njulia> using MicroCollections  # for `EmptyVector` and `SingletonVector`\n\njulia> @floop for x in 1:5\n           ys = SingletonVector(x)\n           if isodd(x)\n               @reduce(odds = append!!(EmptyVector(), ys))\n           else\n               @reduce(evens = append!!(EmptyVector(), ys))\n           end\n       end\n       (odds, evens)\n([1, 3, 5], [2, 4])","category":"page"},{"location":"tutorials/parallel/#Initialization-with-@reduce(acc-init-op-x)-syntax","page":"Parallel loops","title":"Initialization with @reduce(acc = init op x) syntax","text":"","category":"section"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"When op is a binary operator, the infix syntax acc = init op x can also be used:","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"julia> using FLoops\n\njulia> @floop for (x, y) in zip(1:3, 1:2:6)\n           a = x + y\n           b = x - y\n           @reduce(s = 0im + a, t = 0im + b)\n       end\n       (s, t)\n(15 + 0im, -3 + 0im)","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"NOTE: In the above examples, statements like odds = append!!(EmptyVector(), ys) and s = 0im + a are not evaluated for each iteration.  These statements as-is are evaluated only for the first iteration (for each basecase) and then the expressions where the first argument is replaced by the corresponding LHS, i.e., odds = append!!(odds, ys) and s = s + a, are evaluated for the bulk of the loop.","category":"page"},{"location":"tutorials/parallel/#Complex-reduction-with-@reduce()-do-syntax","page":"Parallel loops","title":"Complex reduction with @reduce() do syntax","text":"","category":"section"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"For more complex reduction, use @reduce() do syntax:","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"julia> using FLoops\n\njulia> @floop for (i, v) in pairs([0, 1, 3, 2]), (j, w) in pairs([3, 1, 5])\n           d = abs(v - w)\n           @reduce() do (dmax = -1; d), (imax = 0; i), (jmax = 0; j)\n               if isless(dmax, d)\n                   dmax = d\n                   imax = i\n                   jmax = j\n               end\n           end\n       end\n       (dmax, imax, jmax)\n(5, 1, 3)","category":"page"},{"location":"tutorials/parallel/#How-to-read-a-loop-with-@reduce()-do-syntax","page":"Parallel loops","title":"How to read a loop with @reduce() do syntax","text":"","category":"section"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"When reading code with @reduce() do, a quick way to understand it is to mentally comment out the line with @reduce() do and the corresponding end.  To get a full picture, move the initialization parts (in the above example, dmax = -1, imax = 0, and jmax = 0) to outside for loop:","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"julia> using FLoops\n\njulia> let\n           dmax = -1  # -+\n           imax = 0   #  | initializers\n           jmax = 0   # -+\n           for (i, v) in pairs([0, 1, 3, 2]), (j, w) in pairs([3, 1, 5])\n               d = abs(v - w)\n               if isless(dmax, d)  # -+\n                   dmax = d        #  | `do` block body\n                   imax = i        #  |\n                   jmax = j        #  |\n               end                 # -+\n           end\n           (dmax, imax, jmax)\n       end\n(5, 1, 3)","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"This exact transformation is used for defining the sequential basecase.  Consecutive basecases are combined using the code in the do block body.","category":"page"},{"location":"tutorials/parallel/#Control-flow-syntaxes","page":"Parallel loops","title":"Control flow syntaxes","text":"","category":"section"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"Control flow syntaxes such as continue, break, return, and @goto work with parallel loops:","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"julia> using FLoops\n\njulia> @floop for x in 1:10\n           y = 2x\n           @reduce() do (s; y)\n               s = y\n           end\n           x == 3 && break\n       end\n       s\n6","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"@reduce can be used multiple times in a loop body","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"julia> using FLoops\n\njulia> @floop for (i, v) in pairs([0, 1, 3, 2])\n           y = 2v\n           @reduce() do (ymax; y), (imax; i)\n               if isless(ymax, y)\n                   ymax = y\n                   imax = i\n               end\n           end\n           @reduce() do (ymin; y), (imin; i)\n               if isless(y, ymin)\n                   ymin = y\n                   imin = i\n               end\n           end\n       end\n       (ymax, imax), (ymin, imin)\n((6, 3), (0, 1))","category":"page"},{"location":"tutorials/parallel/#tutorials-executor","page":"Parallel loops","title":"Executors","text":"","category":"section"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"@floop takes optional executor argument to specify an execution strategies and the parameters of the strategy:","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"julia> using FLoops\n\njulia> function demo(executor)\n           @floop executor for x in 1:10\n               @reduce(s += x)\n           end\n           return s\n       end;\n\njulia> demo(SequentialEx(simd = Val(true)))\n55\n\njulia> demo(ThreadedEx(basesize = 2))\n55\n\njulia> demo(DistributedEx(threads_basesize = 2))\n55","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"This is in particular useful for the trick to \"change\" the number of threads without restarting julia using basesize option.","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"JuliaFolds provides additional executors:","category":"page"},{"location":"tutorials/parallel/","page":"Parallel loops","title":"Parallel loops","text":"FoldsThreads.jl provides a rich set of thread-based executors.\nFoldsCUDA.jl provides CUDAEx for executing the parallel loop on GPU.","category":"page"}]
}
